{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import alpaca_trade_api as tradeapi\n",
    "from gym import spaces\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# ======================================\n",
    "# Configuration: Insert your Alpaca Keys\n",
    "# ======================================\n",
    "ALPACA_API_KEY_ID = ''\n",
    "ALPACA_API_SECRET_KEY = \"\"\n",
    "ALPACA_BASE_URL = \"https://paper-api.alpaca.markets\"\n",
    "\n",
    "# ======================================\n",
    "# Continuous Fractional Trading Environment\n",
    "#\n",
    "# Action: a single value in [-1,1].\n",
    "# We map this to a fraction_target in [0,1] of total portfolio value to allocate to the stock.\n",
    "#\n",
    "# fraction_target = (action + 1) / 2\n",
    "#\n",
    "# Each step, we rebalance the portfolio to match the target fraction of the total portfolio\n",
    "# value invested in the stock.\n",
    "#\n",
    "# Reward: Change in portfolio value. Large bonus if we exceed 1.2 * initial cash.\n",
    "# ======================================\n",
    "class ContinuousFractionalTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def _init_(\n",
    "        self,\n",
    "        alpaca_api_key,\n",
    "        alpaca_api_secret,\n",
    "        alpaca_base_url,\n",
    "        ticker=\"F\",\n",
    "        initial_cash=100_000,\n",
    "        lookback_window=1,\n",
    "        start_date=\"2022-01-01\",\n",
    "        end_date=\"2022-06-30\",\n",
    "        timeframe='1Hour'\n",
    "    ):\n",
    "        super(ContinuousFractionalTradingEnv, self)._init_()\n",
    "\n",
    "        self.alpaca_api_key = alpaca_api_key\n",
    "        self.alpaca_api_secret = alpaca_api_secret\n",
    "        self.alpaca_base_url = alpaca_base_url\n",
    "        self.ticker = ticker\n",
    "        self.initial_cash = initial_cash\n",
    "        self.lookback_window = lookback_window\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.timeframe = timeframe\n",
    "\n",
    "        self.api = tradeapi.REST(\n",
    "            self.alpaca_api_key,\n",
    "            self.alpaca_api_secret,\n",
    "            self.alpaca_base_url,\n",
    "            api_version='v2'\n",
    "        )\n",
    "\n",
    "        # Continuous action space: one dimension in [-1,1]\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "\n",
    "        # Observation: OHLCV for lookback steps + shares held + cash\n",
    "        obs_size = (self.lookback_window * 5) + 2\n",
    "        self.observation_space = spaces.Box(low=0.0, high=np.inf, shape=(obs_size,), dtype=np.float32)\n",
    "\n",
    "        self.all_data = self._fetch_historical_data()\n",
    "        self.reset()\n",
    "\n",
    "    def _fetch_historical_data(self):\n",
    "        bars = self.api.get_bars(\n",
    "            symbol=self.ticker,\n",
    "            timeframe=self.timeframe,\n",
    "            start=self.start_date,\n",
    "            end=self.end_date\n",
    "        )\n",
    "        data = pd.DataFrame([{\n",
    "            'time': bar.t,\n",
    "            'open': bar.o,\n",
    "            'high': bar.h,\n",
    "            'low': bar.l,\n",
    "            'close': bar.c,\n",
    "            'volume': bar.v\n",
    "        } for bar in bars])\n",
    "        data.set_index('time', inplace=True)\n",
    "        data.sort_index(inplace=True)\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        return data\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = self.all_data.copy()\n",
    "        self.current_step = self.lookback_window\n",
    "        self.cash = float(self.initial_cash)\n",
    "        self.shares = 0\n",
    "        self.done = False\n",
    "        self.episode_reward = 0.0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        start = self.current_step - self.lookback_window\n",
    "        end = self.current_step\n",
    "        window_data = self.data.iloc[start:end]\n",
    "\n",
    "        obs_data = []\n",
    "        for _, row in window_data.iterrows():\n",
    "            obs_data.extend([\n",
    "                row['open'],\n",
    "                row['high'],\n",
    "                row['low'],\n",
    "                row['close'],\n",
    "                row['volume'],\n",
    "            ])\n",
    "\n",
    "        obs_data.append(self.shares)\n",
    "        obs_data.append(self.cash)\n",
    "        return np.array(obs_data, dtype=np.float32)\n",
    "\n",
    "    def _get_portfolio_value(self):\n",
    "        current_price = self.data.iloc[self.current_step - 1]['close']\n",
    "        return self.cash + (self.shares * current_price)\n",
    "\n",
    "    def step(self, action):\n",
    "        old_portfolio_value = self._get_portfolio_value()\n",
    "\n",
    "        # Map action in [-1,1] to fraction_target in [0,1]\n",
    "        fraction_target = (action[0] + 1) / 2.0\n",
    "        fraction_target = np.clip(fraction_target, 0.0, 1.0)\n",
    "\n",
    "        # Current info\n",
    "        row = self.data.iloc[self.current_step]\n",
    "        current_price = row['close']\n",
    "\n",
    "        # Current total portfolio value\n",
    "        total_value = self._get_portfolio_value()\n",
    "\n",
    "        # Desired shares based on fraction_target\n",
    "        desired_shares = int((fraction_target * total_value) // current_price)\n",
    "\n",
    "        # Buy or sell to reach desired_shares\n",
    "        shares_diff = desired_shares - self.shares\n",
    "        if shares_diff > 0:\n",
    "            # Buy shares_diff shares\n",
    "            cost = shares_diff * current_price\n",
    "            if cost <= self.cash:  # Ensure we have enough cash\n",
    "                self.cash -= cost\n",
    "                self.shares += shares_diff\n",
    "        elif shares_diff < 0:\n",
    "            # Sell -shares_diff shares\n",
    "            shares_to_sell = -shares_diff\n",
    "            self.cash += shares_to_sell * current_price\n",
    "            self.shares -= shares_to_sell\n",
    "\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= len(self.data):\n",
    "            self.done = True\n",
    "\n",
    "        new_portfolio_value = self._get_portfolio_value()\n",
    "        reward = new_portfolio_value - old_portfolio_value\n",
    "\n",
    "        # Big bonus if we reach at least 120% of initial capital\n",
    "        if new_portfolio_value >= (self.initial_cash * 1.2):\n",
    "            reward += 20000\n",
    "            self.done = True\n",
    "\n",
    "        self.episode_reward += reward\n",
    "\n",
    "        print(f\"Step: {self.current_step}, Action: {action[0]:.2f}, Fraction Target: {fraction_target:.2f}, \"\n",
    "              f\"Shares: {self.shares}, Cash: {self.cash:.2f}, Portfolio: {new_portfolio_value:.2f}, Reward: {reward:.2f}\")\n",
    "\n",
    "        if self.done:\n",
    "            print(f\"Episode finished. Total Episode Reward: {self.episode_reward:.2f}\")\n",
    "\n",
    "        obs = self._next_observation() if not self.done else np.zeros(self.observation_space.shape, dtype=np.float32)\n",
    "        info = {'portfolio_value': new_portfolio_value}\n",
    "        return obs, reward, self.done, info\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        portfolio_value = self._get_portfolio_value()\n",
    "        print(f\"Step: {self.current_step}, Shares: {self.shares}, Cash: {self.cash:.2f}, Portfolio: {portfolio_value:.2f}\")\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# Main Script\n",
    "# ======================================\n",
    "if _name_ == \"_main_\":\n",
    "    def make_train_env():\n",
    "        return ContinuousFractionalTradingEnv(\n",
    "            alpaca_api_key=ALPACA_API_KEY_ID,\n",
    "            alpaca_api_secret=ALPACA_API_SECRET_KEY,\n",
    "            alpaca_base_url=ALPACA_BASE_URL,\n",
    "            ticker=\"F\",\n",
    "            initial_cash=100_000,\n",
    "            lookback_window=5,\n",
    "            start_date=\"2014-01-01\",\n",
    "            end_date=\"2022-01-01\",\n",
    "            timeframe='1Hour'\n",
    "        )\n",
    "\n",
    "    train_env = DummyVecEnv([make_train_env])\n",
    "\n",
    "    # Train with DDPG on a continuous action space that represents fractional allocation\n",
    "    model = DDPG(\"MlpPolicy\", train_env, verbose=1)\n",
    "    model.learn(total_timesteps=100_000)\n",
    "\n",
    "    test_env = ContinuousFractionalTradingEnv(\n",
    "        alpaca_api_key=ALPACA_API_KEY_ID,\n",
    "        alpaca_api_secret=ALPACA_API_SECRET_KEY,\n",
    "        alpaca_base_url=ALPACA_BASE_URL,\n",
    "        ticker=\"F\",\n",
    "        initial_cash=100_000,\n",
    "        lookback_window=5,\n",
    "        start_date=\"2022-01-01\",\n",
    "        end_date=\"2023-01-01\",\n",
    "        timeframe='1Hour'\n",
    "    )\n",
    "\n",
    "    obs = test_env.reset()\n",
    "    done = False\n",
    "\n",
    "    times = []\n",
    "    prices = []\n",
    "    shares = []\n",
    "    portfolio_values = []\n",
    "\n",
    "    while not done:\n",
    "        action, _ = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, info = test_env.step(action)\n",
    "        current_step_data = test_env.data.iloc[test_env.current_step - 1]\n",
    "        times.append(test_env.current_step)\n",
    "        prices.append(current_step_data['close'])\n",
    "        shares.append(test_env.shares)\n",
    "        portfolio_values.append(info['portfolio_value'])\n",
    "        test_env.render()\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Graph 1: Price\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(times, prices, label=\"Price\", color=\"blue\")\n",
    "    plt.title(\"Price Over Time\")\n",
    "    plt.xlabel(\"Number of Actions\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Graph 2: Shares\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(times, shares, label=\"Shares\", color=\"green\")\n",
    "    plt.title(\"Shares Over Time\")\n",
    "    plt.xlabel(\"Number of Actions\")\n",
    "    plt.ylabel(\"Shares\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Graph 3: Portfolio Value\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(times, portfolio_values, label=\"Portfolio Value\", color=\"red\")\n",
    "    plt.title(\"Portfolio Value Over Time\")\n",
    "    plt.xlabel(\"Number of Actions\")\n",
    "    plt.ylabel(\"Portfolio Value\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print('Final Portfolio Value:', portfolio_values[-1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
