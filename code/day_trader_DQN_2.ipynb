{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import alpaca_trade_api as tradeapi\n",
    "from gym import spaces\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "# ======================================\n",
    "# 1. Discrete Trading Environment (Buy/Hold/Sell)\n",
    "# ======================================\n",
    "class DiscreteTradingEnvDQN(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def _init_(\n",
    "        self,\n",
    "        alpaca_api_key,\n",
    "        alpaca_api_secret,\n",
    "        alpaca_base_url,\n",
    "        ticker=\"F\",\n",
    "        initial_cash=100_000,\n",
    "        lookback_window=1,\n",
    "        start_date=\"2022-01-01\",\n",
    "        end_date=\"2022-06-30\",\n",
    "        timeframe='1Hour'\n",
    "    ):\n",
    "        super(DiscreteTradingEnvDQN, self)._init_()\n",
    "\n",
    "        self.alpaca_api_key = alpaca_api_key\n",
    "        self.alpaca_api_secret = alpaca_api_secret\n",
    "        self.alpaca_base_url = alpaca_base_url\n",
    "        self.ticker = ticker\n",
    "        self.initial_cash = initial_cash\n",
    "        self.lookback_window = lookback_window\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.timeframe = timeframe\n",
    "\n",
    "        self.api = tradeapi.REST(\n",
    "            self.alpaca_api_key,\n",
    "            self.alpaca_api_secret,\n",
    "            self.alpaca_base_url,\n",
    "            api_version='v2'\n",
    "        )\n",
    "\n",
    "        # Actions: 0 = Sell All, 1 = Hold, 2 = Buy (all-in with available cash)\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # Observation includes OHLCV for lookback_window steps, plus shares held and cash\n",
    "        obs_size = (self.lookback_window * 5) + 2\n",
    "        self.observation_space = spaces.Box(low=0.0, high=np.inf, shape=(obs_size,), dtype=np.float32)\n",
    "\n",
    "        self.all_data = self._fetch_historical_data()\n",
    "        self.reset()\n",
    "\n",
    "    def _fetch_historical_data(self):\n",
    "        bars = self.api.get_bars(\n",
    "            symbol=self.ticker,\n",
    "            timeframe=self.timeframe,\n",
    "            start=self.start_date,\n",
    "            end=self.end_date\n",
    "        )\n",
    "        data = pd.DataFrame([{\n",
    "            'time': bar.t,\n",
    "            'open': bar.o,\n",
    "            'high': bar.h,\n",
    "            'low': bar.l,\n",
    "            'close': bar.c,\n",
    "            'volume': bar.v\n",
    "        } for bar in bars])\n",
    "        data.set_index('time', inplace=True)\n",
    "        data.sort_index(inplace=True)\n",
    "        data.reset_index(drop=True, inplace=True)\n",
    "        return data\n",
    "\n",
    "    def reset(self):\n",
    "        self.data = self.all_data.copy()\n",
    "        self.current_step = self.lookback_window\n",
    "        self.cash = float(self.initial_cash)\n",
    "        self.shares = 0\n",
    "        self.done = False\n",
    "        self.episode_reward = 0.0\n",
    "        self.consecutive_hold_steps = 0\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _next_observation(self):\n",
    "        start = self.current_step - self.lookback_window\n",
    "        end = self.current_step\n",
    "        window_data = self.data.iloc[start:end]\n",
    "\n",
    "        obs_data = []\n",
    "        for _, row in window_data.iterrows():\n",
    "            obs_data.extend([\n",
    "                row['open'],\n",
    "                row['high'],\n",
    "                row['low'],\n",
    "                row['close'],\n",
    "                row['volume'],\n",
    "            ])\n",
    "\n",
    "        # Add shares held and cash as part of the observation\n",
    "        obs_data.append(self.shares)\n",
    "        obs_data.append(self.cash)\n",
    "\n",
    "        return np.array(obs_data, dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        old_portfolio_value = self._get_portfolio_value()\n",
    "\n",
    "        # Current price\n",
    "        row = self.data.iloc[self.current_step]\n",
    "        current_price = row['close']\n",
    "\n",
    "        # Execute action\n",
    "        if action == 0:\n",
    "            # Sell all shares\n",
    "            self.cash += self.shares * current_price\n",
    "            self.shares = 0\n",
    "            self.consecutive_hold_steps = 0  # Reset hold counter\n",
    "        elif action == 1:\n",
    "            # Hold (do nothing)\n",
    "            self.consecutive_hold_steps += 1\n",
    "        elif action == 2:\n",
    "            # Buy as many shares as possible with the available cash\n",
    "            if current_price > 0:\n",
    "                shares_to_buy = int(self.cash // current_price)\n",
    "                self.cash -= shares_to_buy * current_price\n",
    "                self.shares += shares_to_buy\n",
    "            self.consecutive_hold_steps = 0  # Reset hold counter\n",
    "\n",
    "        hold_penalty = 0\n",
    "        if self.consecutive_hold_steps > 50:  # Define the threshold\n",
    "            hold_penalty = -5  # Penalty for holding too long\n",
    "\n",
    "        # Move forward in time\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= len(self.data):\n",
    "            self.done = True\n",
    "\n",
    "        # Compute new portfolio value\n",
    "        new_portfolio_value = self._get_portfolio_value()\n",
    "        reward = new_portfolio_value - old_portfolio_value + hold_penalty\n",
    "\n",
    "\n",
    "        # If portfolio reaches at least 120% of initial cash, end episode immediately and give big reward\n",
    "        if new_portfolio_value >= (self.initial_cash * 1.2):\n",
    "            # Add 20000 to the reward\n",
    "            reward += 20000\n",
    "            self.done = True\n",
    "\n",
    "        \n",
    "        self.episode_reward += reward\n",
    "\n",
    "        print(f\"Step: {self.current_step}, Action: {action}, Shares: {self.shares}, \"\n",
    "              f\"Cash: {self.cash:.2f}, Portfolio: {new_portfolio_value:.2f}, Reward: {reward:.2f}\")\n",
    "\n",
    "        if self.done:\n",
    "            print(f\"Episode finished. Total Episode Reward: {self.episode_reward:.2f}\")\n",
    "\n",
    "        obs = self._next_observation() if not self.done else np.zeros(self.observation_space.shape, dtype=np.float32)\n",
    "        info = {'portfolio_value': new_portfolio_value}\n",
    "        return obs, reward, self.done, info\n",
    "\n",
    "    def _get_portfolio_value(self):\n",
    "        current_price = self.data.iloc[self.current_step - 1]['close']\n",
    "        return self.cash + (self.shares * current_price)\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        portfolio_value = self._get_portfolio_value()\n",
    "        print(f\"Step: {self.current_step}, Shares: {self.shares}, Cash: {self.cash:.2f}, Portfolio: {portfolio_value:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
